{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%file test_lab_3.py\n",
        "\n",
        "\n",
        "from torch.nn.functional import conv_transpose2d\n",
        "import pytest\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def ConvolutionTranspose(input_data, weight_tensor, padding=0, dilation=1, stride=1, groups = 1):\n",
        "\n",
        "    batch_size, in_channels, in_height, in_width = input_data.shape\n",
        "    out_channels, in_channels, kernel_height, kernel_width = weight_tensor.shape\n",
        "\n",
        "    H_out = (in_height - 1) * stride - 2 * padding + kernel_height + padding\n",
        "    W_out = (in_width - 1) * stride - 2 * padding + kernel_width + padding\n",
        "\n",
        "    output = np.zeros((batch_size, out_channels, H_out, W_out))\n",
        "\n",
        "    if padding > 0:\n",
        "        input_data = np.pad(input_data, padding, mode='constant')\n",
        "\n",
        "    output = np.zeros((batch_size, out_channels, H_out, W_out))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for c in range(out_channels):\n",
        "            for i in range(H_out):\n",
        "                for j in range(W_out):\n",
        "                    for k in range(in_channels):\n",
        "                        for s in range(kernel_height):\n",
        "                            for t in range(kernel_width):\n",
        "                                ii = i + padding - s * dilation\n",
        "                                jj = j + padding - t * dilation\n",
        "                                if ii >= 0 and jj >= 0 and ii < in_height * stride and jj < in_width * stride and (ii % stride == 0) and (jj % stride == 0):\n",
        "                                    ii //= stride\n",
        "                                    jj //= stride\n",
        "                                    output[b, c, i, j] += np.multiply(input_data[b, k, ii, jj], weight_tensor[c, k, s, t])\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_1():\n",
        "    image = torch.randn(1, 1, 3, 3)\n",
        "    weight = torch.randn(1, 1, 3, 3)\n",
        "\n",
        "    myConvT = torch.from_numpy(ConvolutionTranspose(image.numpy(), weight.numpy()))\n",
        "\n",
        "    torchConvT = conv_transpose2d(image, weight)\n",
        "\n",
        "    myConvT = myConvT.to(torchConvT.dtype)\n",
        "\n",
        "    assert torch.allclose(myConvT, torchConvT)\n",
        "\n",
        "\n",
        "def test_2():\n",
        "    image = torch.randn(1, 1, 5, 5)\n",
        "    weight = torch.randn(1, 1, 3, 3)\n",
        "\n",
        "    myConvT = torch.from_numpy(ConvolutionTranspose(image.numpy(), weight.numpy()))\n",
        "\n",
        "    torchConvT = conv_transpose2d(image, weight)\n",
        "\n",
        "    myConvT = myConvT.to(torchConvT.dtype)\n",
        "\n",
        "    assert torch.allclose(myConvT, torchConvT)\n",
        "\n",
        "def test_3():\n",
        "    image = torch.randn(1, 1, 5, 5)\n",
        "    weight = torch.randn(1, 1, 3, 3)\n",
        "\n",
        "    myConvT = torch.from_numpy(ConvolutionTranspose(image.numpy(), weight.numpy()))\n",
        "\n",
        "    torchConvT = conv_transpose2d(image, weight)\n",
        "\n",
        "    myConvT = myConvT.to(torchConvT.dtype)\n",
        "\n",
        "    assert torch.allclose(myConvT, torchConvT)\n",
        "\n",
        "def test_4():\n",
        "    image = torch.randn(1, 1, 7, 7)\n",
        "    weight = torch.randn(1, 1, 3, 3)\n",
        "\n",
        "    myConvT = torch.from_numpy(ConvolutionTranspose(image.numpy(), weight.numpy()))\n",
        "\n",
        "    torchConvT = conv_transpose2d(image, weight)\n",
        "\n",
        "    myConvT = myConvT.to(torchConvT.dtype)\n",
        "\n",
        "    assert torch.allclose(myConvT, torchConvT)\n",
        "\n",
        "def test_5():\n",
        "    image = torch.randn(1, 1, 9, 9)\n",
        "    weight = torch.randn(1, 1, 5, 5)\n",
        "\n",
        "    myConvT = torch.from_numpy(ConvolutionTranspose(image.numpy(), weight.numpy()))\n",
        "\n",
        "    torchConvT = conv_transpose2d(image, weight)\n",
        "\n",
        "    myConvT = myConvT.to(torchConvT.dtype)\n",
        "\n",
        "    assert torch.allclose(myConvT, torchConvT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPnDGrSOM9yt",
        "outputId": "4144a7c9-1c38-4175-a35c-f95a0257facf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_lab_3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2sGHvdw653_",
        "outputId": "f4c51ba1-2068-4cab-d526-d7938acc8417"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.3, pluggy-1.3.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 5 items                                                                                  \u001b[0m\n",
            "\n",
            "test_lab_3.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                          [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 2.90s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn(1, 1, 9, 9)\n",
        "weight = torch.randn(1, 1, 5, 5)\n",
        "\n",
        "myConvT = torch.from_numpy(ConvolutionTranspose(image.numpy(), weight.numpy()))\n",
        "print(\"Результат выполнения моей функции ConvolutionTranspose:\")\n",
        "print(myConvT)\n",
        "\n",
        "torchConvT = conv_transpose2d(image, weight)\n",
        "print(\"Результат выполнения встроенной функции conv_transpose2d из библиотеки PyTorch:\")\n",
        "print(torchConvT)\n",
        "\n",
        "myConvT = myConvT.to(torchConvT.dtype)\n",
        "\n",
        "\n",
        "torch.allclose(myConvT, torchConvT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6RM4usgsUcM",
        "outputId": "b4d3543e-55c4-4490-f28f-b25c3e03b1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат выполнения моей функции ConvolutionTranspose:\n",
            "tensor([[[[ 9.4909e-01, -5.7451e-01,  8.9306e-01, -4.4602e-01, -6.0922e-01,\n",
            "            5.4444e-01, -1.8029e+00, -1.2936e+00,  3.4492e-01,  1.4551e-01,\n",
            "           -1.4501e-01, -9.6834e-02, -2.2440e-02],\n",
            "          [-1.1759e-02, -1.9948e+00,  1.5880e+00,  1.2745e-01,  2.5963e+00,\n",
            "           -2.5192e+00,  9.7891e-01,  1.0645e+00,  9.9230e-01,  1.5090e+00,\n",
            "           -5.6474e-01,  5.3950e-02,  2.6525e-01],\n",
            "          [ 7.4824e-02, -2.9715e+00, -2.1657e+00,  4.8301e+00,  3.0426e+00,\n",
            "           -2.9415e+00,  8.1808e-01, -3.5283e+00, -1.0764e+00, -1.5699e+00,\n",
            "            2.5184e+00,  1.3477e+00, -4.3205e-01],\n",
            "          [-3.0911e+00,  2.4124e+00,  5.6406e+00,  8.7986e-01,  2.2736e+00,\n",
            "            4.0089e+00, -4.3301e+00,  5.8070e+00, -7.3173e-01,  1.1121e+00,\n",
            "            1.7933e+00, -1.3215e+00, -1.5420e+00],\n",
            "          [-1.9157e+00,  1.5963e+00,  1.5566e+00, -3.1425e+00, -1.0240e+01,\n",
            "            4.0715e+00,  1.9596e+00, -3.0293e+00,  2.1712e+00, -2.4746e-01,\n",
            "           -6.4070e+00, -5.3490e-01,  2.0691e+00],\n",
            "          [ 2.2009e+00, -7.5933e-01, -8.7131e+00, -1.1950e+00,  5.4811e-01,\n",
            "            3.8574e-01,  8.8520e+00, -7.9018e-01, -3.2337e+00, -4.0758e+00,\n",
            "           -2.9077e+00, -6.1835e-02,  4.7593e+00],\n",
            "          [-4.1461e+00, -2.2364e+00, -3.5619e+00, -5.3192e+00,  1.1639e+01,\n",
            "           -5.1577e+00, -1.2230e+01,  3.4381e+00, -1.2250e+00, -1.7599e+00,\n",
            "            6.3235e+00,  5.0917e-01, -6.5811e+00],\n",
            "          [-1.8437e+00, -2.2871e+00,  5.9456e+00,  8.5124e+00, -6.4749e+00,\n",
            "            3.7753e+00,  8.8133e-01, -4.3187e+00,  7.1808e+00,  7.4153e+00,\n",
            "            3.5502e+00,  2.0736e+00, -1.5457e-01],\n",
            "          [-3.5744e+00,  1.1650e+00,  2.7909e+00,  2.4726e+00, -2.9554e+00,\n",
            "           -6.9796e+00,  5.4996e+00,  1.8264e+00, -5.5544e+00,  7.6398e+00,\n",
            "            1.6429e-01, -5.0345e+00,  1.1360e+00],\n",
            "          [-1.1542e+00, -7.7906e-01, -2.0522e+00,  8.2946e-01,  2.2191e+00,\n",
            "            6.3192e-01, -2.4893e+00,  3.6487e-01,  7.6200e+00, -5.0275e+00,\n",
            "            8.0094e-01,  2.9365e+00, -1.5024e+00],\n",
            "          [-7.1895e-02, -5.1379e+00, -3.5215e+00, -2.0741e+00,  1.9583e+00,\n",
            "           -2.4844e+00, -7.4374e+00, -3.1537e+00, -2.0675e+00,  1.1589e-01,\n",
            "           -2.5268e+00, -2.7808e-01,  3.4432e+00],\n",
            "          [-9.5598e-01, -5.6541e+00, -4.3398e+00,  2.1750e-01,  3.3758e+00,\n",
            "           -6.1343e+00, -4.4104e+00, -6.2147e+00, -7.7017e+00, -1.1325e+00,\n",
            "           -8.7977e-01,  3.4523e+00, -1.1270e+00],\n",
            "          [ 1.0055e+00, -2.8595e+00, -4.5339e-01,  1.1271e+00, -1.2004e+00,\n",
            "            1.6971e+00, -2.8537e+00, -1.4042e+00, -7.0383e-01, -1.2624e+00,\n",
            "            6.3965e-01, -7.5155e-01,  9.4575e-02]]]], dtype=torch.float64)\n",
            "Результат выполнения встроенной функции conv_transpose2d из библиотеки PyTorch:\n",
            "tensor([[[[ 9.4909e-01, -5.7451e-01,  8.9306e-01, -4.4602e-01, -6.0922e-01,\n",
            "            5.4444e-01, -1.8029e+00, -1.2936e+00,  3.4492e-01,  1.4551e-01,\n",
            "           -1.4501e-01, -9.6834e-02, -2.2440e-02],\n",
            "          [-1.1759e-02, -1.9948e+00,  1.5880e+00,  1.2745e-01,  2.5963e+00,\n",
            "           -2.5192e+00,  9.7891e-01,  1.0645e+00,  9.9230e-01,  1.5090e+00,\n",
            "           -5.6474e-01,  5.3950e-02,  2.6525e-01],\n",
            "          [ 7.4824e-02, -2.9715e+00, -2.1657e+00,  4.8301e+00,  3.0426e+00,\n",
            "           -2.9415e+00,  8.1808e-01, -3.5283e+00, -1.0764e+00, -1.5699e+00,\n",
            "            2.5184e+00,  1.3477e+00, -4.3205e-01],\n",
            "          [-3.0911e+00,  2.4124e+00,  5.6406e+00,  8.7986e-01,  2.2736e+00,\n",
            "            4.0089e+00, -4.3301e+00,  5.8070e+00, -7.3173e-01,  1.1121e+00,\n",
            "            1.7933e+00, -1.3215e+00, -1.5420e+00],\n",
            "          [-1.9157e+00,  1.5963e+00,  1.5566e+00, -3.1425e+00, -1.0240e+01,\n",
            "            4.0715e+00,  1.9596e+00, -3.0293e+00,  2.1712e+00, -2.4746e-01,\n",
            "           -6.4070e+00, -5.3490e-01,  2.0691e+00],\n",
            "          [ 2.2009e+00, -7.5933e-01, -8.7131e+00, -1.1950e+00,  5.4811e-01,\n",
            "            3.8574e-01,  8.8520e+00, -7.9018e-01, -3.2337e+00, -4.0758e+00,\n",
            "           -2.9077e+00, -6.1835e-02,  4.7593e+00],\n",
            "          [-4.1461e+00, -2.2364e+00, -3.5619e+00, -5.3192e+00,  1.1639e+01,\n",
            "           -5.1577e+00, -1.2230e+01,  3.4381e+00, -1.2250e+00, -1.7599e+00,\n",
            "            6.3235e+00,  5.0917e-01, -6.5811e+00],\n",
            "          [-1.8437e+00, -2.2871e+00,  5.9456e+00,  8.5124e+00, -6.4749e+00,\n",
            "            3.7753e+00,  8.8133e-01, -4.3187e+00,  7.1808e+00,  7.4153e+00,\n",
            "            3.5502e+00,  2.0736e+00, -1.5457e-01],\n",
            "          [-3.5744e+00,  1.1650e+00,  2.7909e+00,  2.4726e+00, -2.9554e+00,\n",
            "           -6.9796e+00,  5.4996e+00,  1.8264e+00, -5.5544e+00,  7.6398e+00,\n",
            "            1.6429e-01, -5.0345e+00,  1.1360e+00],\n",
            "          [-1.1542e+00, -7.7906e-01, -2.0522e+00,  8.2946e-01,  2.2191e+00,\n",
            "            6.3192e-01, -2.4893e+00,  3.6487e-01,  7.6200e+00, -5.0275e+00,\n",
            "            8.0094e-01,  2.9365e+00, -1.5024e+00],\n",
            "          [-7.1895e-02, -5.1379e+00, -3.5215e+00, -2.0741e+00,  1.9583e+00,\n",
            "           -2.4844e+00, -7.4374e+00, -3.1537e+00, -2.0675e+00,  1.1589e-01,\n",
            "           -2.5268e+00, -2.7808e-01,  3.4432e+00],\n",
            "          [-9.5598e-01, -5.6541e+00, -4.3398e+00,  2.1750e-01,  3.3758e+00,\n",
            "           -6.1343e+00, -4.4104e+00, -6.2147e+00, -7.7017e+00, -1.1325e+00,\n",
            "           -8.7977e-01,  3.4523e+00, -1.1270e+00],\n",
            "          [ 1.0055e+00, -2.8595e+00, -4.5339e-01,  1.1271e+00, -1.2004e+00,\n",
            "            1.6971e+00, -2.8537e+00, -1.4042e+00, -7.0383e-01, -1.2624e+00,\n",
            "            6.3965e-01, -7.5155e-01,  9.4575e-02]]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}